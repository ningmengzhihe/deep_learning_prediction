{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99de7597",
   "metadata": {},
   "source": [
    "# extract features of transformer[ok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c15c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis Tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff916b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e7f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer for time series Class\n",
    "from utils.transformers_tst.tst import Transformer\n",
    "from utils.transformers_tst.src.utils import compute_loss\n",
    "from utils.transformers_tst.src.visualization import map_plot_function, plot_values_distribution, plot_error_distribution, plot_errors_threshold, plot_visual_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b373d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot curve\n",
    "import utils.functions_plot as PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ccefcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (798, 263, 19)\n",
      "y_train shape:  (798, 1)\n",
      "X_test shape:  (165, 263, 19)\n",
      "y_test shape:  (165, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load phm2016 cmp dataset\n",
    "X_train = np.load(\"./data phm 2016/X_train_r_modeI_chamber4_mm.npy\")\n",
    "y_train = np.load(\"./data phm 2016/y_train_modeI_chamber4_mm.npy\")\n",
    "X_test = np.load(\"./data phm 2016/X_test_r_modeI_chamber4_mm.npy\")\n",
    "y_test = np.load(\"./data phm 2016/y_test_modeI_chamber4_mm.npy\")\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363ebcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集晶圆个数： 798\n",
      "最长时间序列长度： 263\n",
      "字段个数： 19\n",
      "训练集晶圆个数： 165\n"
     ]
    }
   ],
   "source": [
    "# 基本参数\n",
    "wafer_number, max_batch_length, variable_number = X_train.shape\n",
    "wafer_number_test = X_test.shape[0]\n",
    "print('训练集晶圆个数：', wafer_number)\n",
    "print('最长时间序列长度：', max_batch_length)\n",
    "print('字段个数：', variable_number)\n",
    "print('训练集晶圆个数：', wafer_number_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea4e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMPModeIChamber4Dataset(Dataset):\n",
    "    \"\"\"Torch dataset for Oze datachallenge training.\n",
    "    Attributes\n",
    "    ----------\n",
    "    x: np.array\n",
    "        Dataset target of shape (wafer_number, seq_length, variable_number).\n",
    "    \n",
    "    y: np.array\n",
    "        Dataset target of shape (wafer_number, 1).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_x, dataset_y, **kwargs):\n",
    "        \"\"\"Load dataset from csv.\n",
    "        Parameters\n",
    "        ---------\n",
    "        dataset_x: Tuple\n",
    "            Tuple of shape (wafer_number, seq_length, variable_number).\n",
    "        dataset_y: Tuple\n",
    "            Tuple of shape (wafer_number, 1).\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self._x = dataset_x.astype(np.float32)\n",
    "        self._y = dataset_y.astype(np.float32)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return (self._x[idx], self._y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._x.shape[0]\n",
    "\n",
    "    def get_x_shape(self):\n",
    "        \"\"\"get_x_shape\"\"\"\n",
    "        return self._x.shape\n",
    "\n",
    "    def get_y_shape(self):\n",
    "        \"\"\"get_y_shape\"\"\"\n",
    "        return self._y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6a1378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_train = CMPModeIChamber4Dataset(X_train, y_train)\n",
    "cmp_test = CMPModeIChamber4Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d3ab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_WORKERS = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7327dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(cmp_train,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              pin_memory=False\n",
    "                             )\n",
    "dataloader_test = DataLoader(cmp_test,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=NUM_WORKERS\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cfff785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load re-training net\n",
    "net = pickle.load(open('./results_save/tensforflow_without_validation/epocha400_batchsize100_net-2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7eda367",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (layers_encoding): ModuleList(\n",
      "    (0): Encoder(\n",
      "      (_selfAttention): MultiHeadAttention(\n",
      "        (_W_q): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_k): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_v): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_o): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "      (_feedForward): PositionwiseFeedForward(\n",
      "        (_linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "        (_linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "      )\n",
      "      (_layerNorm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (_layerNorm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (_dopout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (1): Encoder(\n",
      "      (_selfAttention): MultiHeadAttention(\n",
      "        (_W_q): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_k): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_v): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_o): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "      (_feedForward): PositionwiseFeedForward(\n",
      "        (_linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "        (_linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "      )\n",
      "      (_layerNorm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (_layerNorm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (_dopout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (layers_decoding): ModuleList(\n",
      "    (0): Decoder(\n",
      "      (_selfAttention): MultiHeadAttention(\n",
      "        (_W_q): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_k): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_v): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_o): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "      (_encoderDecoderAttention): MultiHeadAttention(\n",
      "        (_W_q): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_k): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_v): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_o): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "      (_feedForward): PositionwiseFeedForward(\n",
      "        (_linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "        (_linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "      )\n",
      "      (_layerNorm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (_layerNorm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (_layerNorm3): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (_dopout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (1): Decoder(\n",
      "      (_selfAttention): MultiHeadAttention(\n",
      "        (_W_q): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_k): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_v): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_o): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "      (_encoderDecoderAttention): MultiHeadAttention(\n",
      "        (_W_q): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_k): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_v): Linear(in_features=8, out_features=16, bias=True)\n",
      "        (_W_o): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "      (_feedForward): PositionwiseFeedForward(\n",
      "        (_linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "        (_linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "      )\n",
      "      (_layerNorm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (_layerNorm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (_layerNorm3): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "      (_dopout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (_embedding): Linear(in_features=19, out_features=8, bias=True)\n",
      "  (_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (_flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (_output): Linear(in_features=263, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572f808",
   "metadata": {},
   "source": [
    "# extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1007ddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers_encoding\n",
      "0\n",
      "1\n",
      "layers_decoding\n",
      "0\n",
      "1\n",
      "_embedding\n",
      "_linear\n",
      "_flatten\n",
      "_output\n"
     ]
    }
   ],
   "source": [
    "for name, module in net._modules.items():\n",
    "    print(name)\n",
    "    if name=='layers_encoding':\n",
    "        for n, m in module._modules.items():\n",
    "            print(n)\n",
    "            if n=='0':\n",
    "                module_encoding_0 = m\n",
    "            elif n=='1':\n",
    "                module_encoding_1 = m\n",
    "    elif name=='layers_decoding':\n",
    "        for n, m in module._modules.items():\n",
    "            print(n)\n",
    "            if n=='0':\n",
    "                module_decoding_0 = m\n",
    "            elif n=='1':\n",
    "                module_decoding_1 = m\n",
    "    elif name=='_embedding':\n",
    "        module_embedding = module\n",
    "    elif name=='_linear':\n",
    "        module_linear = module\n",
    "    elif name=='_flatten':\n",
    "        module_flatten = module\n",
    "    elif name=='_output':\n",
    "        module_output = module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "659faf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出test，缺少stack\n",
    "def extract_transformer_features(dataloader:DataLoader):\n",
    "    predictions = np.empty(shape=(len(dataloader.dataset), 263))\n",
    "    idx_prediction = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(dataloader, total=len(dataloader)):\n",
    "            K = x.shape[1]\n",
    "            # embedding\n",
    "            embedding = module_embedding(x)\n",
    "            # positional embedding for encoding\n",
    "            pe_params = {'period': net._pe_period} if net._pe_period else {}\n",
    "            positional_encoding = net._generate_PE(K, net._d_model, **pe_params)\n",
    "            positional_encoding = positional_encoding.to(embedding.device)\n",
    "            embedding.add_(positional_encoding)\n",
    "            # 2 layer encoder\n",
    "            encoding_0 = module_encoding_0(embedding)\n",
    "            encoding_1 = module_encoding_1(encoding_0)\n",
    "            \n",
    "            # decoding\n",
    "            decoding_0 = encoding_1\n",
    "            # positional embedding for decoding\n",
    "            positional_encoding = net._generate_PE(K, net._d_model)\n",
    "            positional_encoding = positional_encoding.to(decoding_0.device)\n",
    "            decoding_0.add_(positional_encoding)\n",
    "            # 2 layer decoder\n",
    "            decoding_0 = module_decoding_0(decoding_0, encoding_1)\n",
    "            decoding_1 = module_decoding_1(decoding_0, encoding_1)\n",
    "            # linear\n",
    "            linear = module_linear(decoding_1)\n",
    "            # flatten\n",
    "            flatten = module_flatten(linear)\n",
    "\n",
    "            predictions[idx_prediction:idx_prediction+x.shape[0]] = flatten\n",
    "            idx_prediction += x.shape[0]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa3fcd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:12<00:00,  1.56s/it]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798, 263) (165, 263)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train = extract_transformer_features(dataloader=dataloader_train)\n",
    "predictions_test = extract_transformer_features(dataloader=dataloader_test)\n",
    "print(predictions_train.shape,predictions_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cddcbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "pickle.dump(predictions_train, open('./results_save/tensforflow_without_validation/features_tf_withoutPE_train.pkl', 'wb'))\n",
    "pickle.dump(predictions_test, open('./results_save/tensforflow_without_validation/features_tf_withoutPE_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ff40c",
   "metadata": {},
   "source": [
    "# Define new struction[not ok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "962cb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransformerFlatten(Transformer):\n",
    "#     def __init__(self, net:Transformer):\n",
    "#         super().__init__()\n",
    "#         self.model = nn.Sequential()\n",
    "#         self.model.add_module(name='linear_1', module=list(net.children())[2]) #Linear(in_features=19, out_features=8, bias=True)\n",
    "#         self.model.add_module(name='encoder', module=list(net.children())[0]) # encoder\n",
    "#         self.model.add_module(name='decoder', module=list(net.children())[1]) # decoder\n",
    "#         self.model.add_module(name='linear_2', module=list(net.children())[3]) # Linear(in_features=8, out_features=1, bias=True)\n",
    "#         self.model.add_module(name='flatten', module=list(net.children())[4]) # flatten\n",
    "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d335e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_net = nn.Sequential()\n",
    "# new_net.add_module(name='linear_1', module=list(net.children())[2]) #Linear(in_features=19, out_features=8, bias=True)\n",
    "# new_net.add_module(name='encoder', module=list(net.children())[0]) # encoder\n",
    "# new_net.add_module(name='decoder', module=list(net.children())[1]) # decoder\n",
    "# new_net.add_module(name='linear_2', module=list(net.children())[3]) # Linear(in_features=8, out_features=1, bias=True)\n",
    "# new_net.add_module(name='flatten', module=list(net.children())[4]) # flatten\n",
    "# print(new_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ece2becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_net = TransformerFlatten(net)\n",
    "# print(new_net.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0b67a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some layers before flattern\n",
    "# new_model = nn.Sequential(list(net.children())[5])\n",
    "# new_model = nn.Sequential(*list(net.children())[:6])\n",
    "# print\n",
    "#0:encoder; 1:decoder; *\n",
    "#2:Linear(in_features=19, out_features=8, bias=True)\n",
    "#3:Linear(in_features=8, out_features=1, bias=True)\n",
    "#4:Flatten(start_dim=1, end_dim=-1)\n",
    "#5:Linear(in_features=263, out_features=1, bias=True)\n",
    "#sequence: 2/*0/*1/3/4/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e85dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b808d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_new_net(net:nn.Module, dataloader:DataLoader):\n",
    "#     predictions = np.empty(shape=(len(dataloader.dataset), 1))\n",
    "\n",
    "#     idx_prediction = 0\n",
    "#     with torch.no_grad():\n",
    "#         for x, y in tqdm(dataloader, total=len(dataloader)):\n",
    "#             netout = net(x.to(device)).cpu().numpy()\n",
    "#             predictions[idx_prediction:idx_prediction+x.shape[0]] = netout\n",
    "#             idx_prediction += x.shape[0]\n",
    "            \n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29dc3e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = x.to(device)\n",
    "# out = list(net.children())[2](out)\n",
    "# out = list(net.children())[0][0](out)\n",
    "# out = list(net.children())[0][1](out)\n",
    "# out = list(net.children())[1][0](out)\n",
    "# out = list(net.children())[1][1](out)\n",
    "# out = list(net.children())[3](out)\n",
    "# out = list(net.children())[4](out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e50f8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(net.children())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0158b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict for train\n",
    "# predictions_train = predict_new_net(new_net, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2cee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
